{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dd3cc58",
   "metadata": {
    "papermill": {
     "duration": 0.003713,
     "end_time": "2025-07-30T19:40:12.526016",
     "exception": false,
     "start_time": "2025-07-30T19:40:12.522303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## My Submission for Spaceship Titanic\n",
    "\n",
    "We start by importing our training, testing, and submission files to our program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33017f5b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-30T19:40:12.533894Z",
     "iopub.status.busy": "2025-07-30T19:40:12.533586Z",
     "iopub.status.idle": "2025-07-30T19:40:16.093073Z",
     "shell.execute_reply": "2025-07-30T19:40:16.092088Z"
    },
    "papermill": {
     "duration": 3.565085,
     "end_time": "2025-07-30T19:40:16.094535",
     "exception": false,
     "start_time": "2025-07-30T19:40:12.529450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/spaceship-titanic/sample_submission.csv\n",
      "/kaggle/input/spaceship-titanic/train.csv\n",
      "/kaggle/input/spaceship-titanic/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "all_features = [\"PassengerID\", \"HomePlanet\", \"CryoSleep\", \"Cabin\", \"Destination\", \"Age\", \n",
    "            \"VIP\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\", \"Name\"]\n",
    "\n",
    "#Some observations\n",
    "\n",
    "#train_data[[\"HomePlanet\", \"Transported\"]].groupby([\"HomePlanet\", \"Transported\"]).agg(len).apply(lambda x:x)\n",
    "#Curiously, around 2/3 of people from europa are transported\n",
    "\n",
    "#train_data[[\"CryoSleep\", \"Transported\"]].groupby([\"CryoSleep\", \"Transported\"]).agg(len).apply(lambda x:x)\n",
    "#People not in CryoSleep are less likely to get transported than people who are in CryoSleep\n",
    "\n",
    "#view_data([\"Destination\", \"Transported\"], train_data).apply(lambda x:x)\n",
    "#61 percent of people going to 55 Cancri were transported\n",
    "\n",
    "#def brackets(step, price):\n",
    "#    return np.floor(price/step)\n",
    "\n",
    "#bracket = 800\n",
    "#train_data[\"Expenses\"] = train_data[\"Expenses\"].map(lambda x: brackets(bracket, x))\n",
    "\n",
    "#view_data([\"Expenses\", \"Transported\"], train_data).apply(lambda x:x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367f4853",
   "metadata": {
    "papermill": {
     "duration": 0.002902,
     "end_time": "2025-07-30T19:40:16.100793",
     "exception": false,
     "start_time": "2025-07-30T19:40:16.097891",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We then want to determine what factors would lead to someone being transported. The first thing I noticed is that if a passenger was a VIP, then they were less likely to be transported, so this seemed to be a pretty good feature to focus on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4c67b4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T19:40:16.108432Z",
     "iopub.status.busy": "2025-07-30T19:40:16.107966Z",
     "iopub.status.idle": "2025-07-30T19:40:16.185591Z",
     "shell.execute_reply": "2025-07-30T19:40:16.184570Z"
    },
    "papermill": {
     "duration": 0.083267,
     "end_time": "2025-07-30T19:40:16.187149",
     "exception": false,
     "start_time": "2025-07-30T19:40:16.103882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01735952489721334"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"/kaggle/input/spaceship-titanic/train.csv\")\n",
    "\n",
    "transported_data = train_data[train_data[\"Transported\"] == True]\n",
    "num_transported = len(transported_data)\n",
    "\n",
    "VIP_data = train_data[train_data[\"VIP\"] == True]\n",
    "VIP_transport_percentage = len(VIP_data[VIP_data[\"Transported\"] == True])/num_transported\n",
    "\n",
    "VIP_transport_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74555677",
   "metadata": {
    "papermill": {
     "duration": 0.003087,
     "end_time": "2025-07-30T19:40:16.193613",
     "exception": false,
     "start_time": "2025-07-30T19:40:16.190526",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It turns out that only 1.7359% of VIPs were transported! VIPs are usually pretty rich, so it is natural to ask how one's personal wealth influences whether or not they were transported. But, there is no \"Wealth\" column in our table, however, we can guess how much wealth one had based on how much they spent. In otherwords, we can determine's one wealth based on their expenses, which we calculate in the following way: $$Expenses = RoomService + FoodCourt + ShoppingMall + Spa + VRDeck$$ Here is the corresponding the code that goes with this calculation and its visualization in a table format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "979a1599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T19:40:16.201710Z",
     "iopub.status.busy": "2025-07-30T19:40:16.200872Z",
     "iopub.status.idle": "2025-07-30T19:40:16.240059Z",
     "shell.execute_reply": "2025-07-30T19:40:16.239100Z"
    },
    "papermill": {
     "duration": 0.044616,
     "end_time": "2025-07-30T19:40:16.241511",
     "exception": false,
     "start_time": "2025-07-30T19:40:16.196895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bracket_Expenses  Transported\n",
       "0.0               False          1463\n",
       "                  True           2854\n",
       "1.0               False          1133\n",
       "                  True            478\n",
       "2.0               False           424\n",
       "                                 ... \n",
       "35.0              False             1\n",
       "37.0              False             1\n",
       "38.0              False             1\n",
       "                  True              2\n",
       "44.0              False             1\n",
       "Length: 64, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Expenses\"] = train_data[\"RoomService\"] + train_data[\"FoodCourt\"] + train_data[\"ShoppingMall\"] + train_data[\"Spa\"] + train_data[\"VRDeck\"]\n",
    "\n",
    "#Generates a table showing how many people have these characteristics\n",
    "def view_data(characteristics, dataset):\n",
    "    return dataset[characteristics].groupby(characteristics).agg(len)\n",
    "\n",
    "#A function which takes a price and puts it into a price range [step * i, step * (i + 1)) determined by step (a money value), \n",
    "#and the bracket that person\n",
    "def brackets(step, price):\n",
    "    return np.floor(price/step)\n",
    "\n",
    "bracket = 800\n",
    "train_data[\"Bracket_Expenses\"] = train_data[\"Expenses\"].map(lambda x: brackets(bracket, x))\n",
    "\n",
    "view_data([\"Bracket_Expenses\", \"Transported\"], train_data).apply(lambda x:x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501f6f04",
   "metadata": {
    "papermill": {
     "duration": 0.003035,
     "end_time": "2025-07-30T19:40:16.247974",
     "exception": false,
     "start_time": "2025-07-30T19:40:16.244939",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Unsurprisingly, people with less money (in 0th Expenses bracket where each bracket is divided by 800 space bucks) were more likely to be transported than people who had more money. However, this statistic does not account for people in CryoSleep or where people were during the temporal anomaly. I have not yet implemented CryoSleep into my model, but I have analyzed the relationship between cabin locations and transportations. In order to analyze this relation, I decided to parse and process the cabin location, which is given by Deck/Num/Port, so that Deck and Num are numeric and that people without a cabin are sent to $/1000/N, which doesn't exist. Here is the code I used to clean the cabin locations as well as some observations I made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e09f01a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T19:40:16.256468Z",
     "iopub.status.busy": "2025-07-30T19:40:16.255487Z",
     "iopub.status.idle": "2025-07-30T19:40:16.387795Z",
     "shell.execute_reply": "2025-07-30T19:40:16.386960Z"
    },
    "papermill": {
     "duration": 0.138024,
     "end_time": "2025-07-30T19:40:16.389260",
     "exception": false,
     "start_time": "2025-07-30T19:40:16.251236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Deck  Transported\n",
       "36    False            99\n",
       "      True            100\n",
       "65    False           129\n",
       "      True            127\n",
       "66    False           207\n",
       "      True            572\n",
       "67    False           239\n",
       "      True            508\n",
       "68    False           271\n",
       "      True            207\n",
       "69    False           563\n",
       "      True            313\n",
       "70    False          1565\n",
       "      True           1229\n",
       "71    False          1238\n",
       "      True           1321\n",
       "84    False             4\n",
       "      True              1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_cabin(cabin):\n",
    "    if type(cabin) != str:\n",
    "        return \"$/1000/N\" #If a person doesn't have a cabin\n",
    "    else:\n",
    "        return cabin\n",
    "\n",
    "train_data[\"Cabin\"] = train_data[\"Cabin\"].map(clean_cabin)\n",
    "attributes = train_data[\"Cabin\"].map(lambda x: x.split(\"/\"))\n",
    "\n",
    "train_data[\"Deck\"] = list(map(lambda x: ord(x[0][0]), attributes))\n",
    "train_data[\"Num\"] = list(map(lambda x: int(x[1]), attributes))\n",
    "train_data[\"Side\"] = list(map(lambda x: x[2], attributes))\n",
    "\n",
    "view_data([\"Side\", \"Transported\"], train_data).apply(lambda x: x)\n",
    "#On side N, ~50% chance of getting transported\n",
    "#On side P, ~46% chance of getting transported (4206 people total)\n",
    "#On side S, ~55% chance of getting transpoted (4288 people total)\n",
    "\n",
    "view_data([\"Deck\", \"Transported\"], train_data).apply(lambda x: x)\n",
    "#Decks B, C seem relatively unsafe, E seems pretty safe, on Deck F only ~46% were transported\n",
    "#A lot of people are on decks F and G\n",
    "\n",
    "view_data([\"Deck\", \"Transported\"], train_data).apply(lambda x: x)\n",
    "#It seems like people who shared a room were either mostly fine or not fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd43a2b",
   "metadata": {
    "papermill": {
     "duration": 0.003071,
     "end_time": "2025-07-30T19:40:16.395863",
     "exception": false,
     "start_time": "2025-07-30T19:40:16.392792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I also noticed that the majority of passenger are below 40 years old. However, it seems like those below twenty are more likely to be transported than those in higher 20 year age brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56ab10ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T19:40:16.403553Z",
     "iopub.status.busy": "2025-07-30T19:40:16.403269Z",
     "iopub.status.idle": "2025-07-30T19:40:16.428696Z",
     "shell.execute_reply": "2025-07-30T19:40:16.427777Z"
    },
    "papermill": {
     "duration": 0.03103,
     "end_time": "2025-07-30T19:40:16.430209",
     "exception": false,
     "start_time": "2025-07-30T19:40:16.399179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age_Bracket  Transported\n",
       "0.0          False           887\n",
       "             True           1271\n",
       "1.0          False          2405\n",
       "             True           2092\n",
       "2.0          False           799\n",
       "             True            806\n",
       "3.0          False           135\n",
       "             True            119\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_bracket = 20\n",
    "train_data[\"Age_Bracket\"] = train_data[\"Age\"].map(lambda x: brackets(age_bracket, x))\n",
    "\n",
    "view_data([\"Age_Bracket\", \"Transported\"], train_data).map(lambda x: x)\n",
    "#When age_bracket = 20, we see that most people are below 40 years old, but those below twenty are more likely to be transported."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec51f7d6",
   "metadata": {
    "papermill": {
     "duration": 0.003275,
     "end_time": "2025-07-30T19:40:16.437400",
     "exception": false,
     "start_time": "2025-07-30T19:40:16.434125",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Based on these observations, I decided to create a small model based on Expenses, Deck, room number, Age, and VIP status to predict whether someone was transported. But first, I had to create a function that cleaned the data appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1bfab33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T19:40:16.446796Z",
     "iopub.status.busy": "2025-07-30T19:40:16.446016Z",
     "iopub.status.idle": "2025-07-30T19:40:16.454278Z",
     "shell.execute_reply": "2025-07-30T19:40:16.453528Z"
    },
    "papermill": {
     "duration": 0.013977,
     "end_time": "2025-07-30T19:40:16.455703",
     "exception": false,
     "start_time": "2025-07-30T19:40:16.441726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_cabin(cabin):\n",
    "    if type(cabin) != str:\n",
    "        return \"$/1000/N\" #If a person doesn't have a cabin\n",
    "    else:\n",
    "        return cabin\n",
    "\n",
    "def transform_data(data):\n",
    "    ord_encoder = OrdinalEncoder()\n",
    "    \n",
    "    data[\"VIP\"] = data[\"VIP\"].fillna(False).astype(bool)\n",
    "    data[\"VIP\"] = data[\"VIP\"].map(lambda x: int(x == True))\n",
    "    \n",
    "    data[\"CryoSleep\"] = data[\"CryoSleep\"].fillna(False).astype(bool)\n",
    "    data[\"CryoSleep\"] = data[\"CryoSleep\"].map(lambda x: int(x == True))\n",
    "    \n",
    "    data[\"Cabin\"] = data[\"Cabin\"].map(clean_cabin)\n",
    "    attributes = data[\"Cabin\"].map(lambda x: x.split(\"/\"))\n",
    "\n",
    "    data[\"Deck\"] = list(map(lambda x: x[0][0], attributes))\n",
    "    data[\"Num\"] = list(map(lambda x: x[1], attributes))\n",
    "    data[\"Side\"] = list(map(lambda x: x[2], attributes))\n",
    "\n",
    "    data[[\"Deck\", \"Num\", \"Side\"]] = ord_encoder.fit_transform(data[[\"Deck\", \"Num\", \"Side\"]])\n",
    "\n",
    "    data[\"Age\"] = data[\"Age\"].fillna(1000).astype(float) #I chose this value because no one is above 1000 years old\n",
    "    \n",
    "    purchases = [\"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\n",
    "    data[\"Expenses\"] = sum([data[item] for item in purchases])\n",
    "    data[\"Expenses\"] = data[\"Expenses\"].fillna(0).astype(float)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06535943",
   "metadata": {
    "papermill": {
     "duration": 0.00328,
     "end_time": "2025-07-30T19:40:16.462639",
     "exception": false,
     "start_time": "2025-07-30T19:40:16.459359",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here is my model. (Make sure to run the cell above to clean the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47132a0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T19:40:16.471290Z",
     "iopub.status.busy": "2025-07-30T19:40:16.470938Z",
     "iopub.status.idle": "2025-07-30T19:40:19.179234Z",
     "shell.execute_reply": "2025-07-30T19:40:19.177908Z"
    },
    "papermill": {
     "duration": 2.714447,
     "end_time": "2025-07-30T19:40:19.180719",
     "exception": false,
     "start_time": "2025-07-30T19:40:16.466272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/1042144398.py:10: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"VIP\"] = data[\"VIP\"].fillna(False).astype(bool)\n",
      "/tmp/ipykernel_13/1042144398.py:13: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"CryoSleep\"] = data[\"CryoSleep\"].fillna(False).astype(bool)\n",
      "/tmp/ipykernel_13/1042144398.py:10: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"VIP\"] = data[\"VIP\"].fillna(False).astype(bool)\n",
      "/tmp/ipykernel_13/1042144398.py:13: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"CryoSleep\"] = data[\"CryoSleep\"].fillna(False).astype(bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2622196664749856\n",
      "133\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def score(estimators, data_train, data_test, val_train, val_test):\n",
    "    rfc = RandomForestClassifier(n_estimators = estimators, random_state=0).fit(data_train, val_train)\n",
    "    return mean_absolute_error(rfc.predict(data_test), val_test)\n",
    "\n",
    "train_data = transform_data(train_data)\n",
    "test_data = transform_data(pd.read_csv('/kaggle/input/spaceship-titanic/test.csv'))\n",
    "train_features = [\"Expenses\", \"Deck\", \"Num\", \"Side\", \"VIP\", \"CryoSleep\", \"Age\"]\n",
    "\n",
    "X = train_data[train_features]\n",
    "y = train_data[\"Transported\"].map(lambda x: int(x))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "#rfc = RandomForestClassifier(n_estimators=50, random_state=0).fit(X_train, y_train)\n",
    "#predictions = rfc.predict(X_test)\n",
    "\n",
    "#estims = range(1, 140, 1)\n",
    "#best_index = np.argmin(list(map(lambda x: score(x, X_train, X_test, y_train, y_test), estims)))\n",
    "#best_value = estims[best_index]\n",
    "#The lines above were used to determine how many estimators I should use in my model\n",
    "\n",
    "best_value = 133\n",
    "my_model = RandomForestClassifier(n_estimators = best_value, random_state=0).fit(X_train, y_train)\n",
    "\n",
    "print(score(best_value, X_train, X_test, y_train, y_test))\n",
    "print(best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39940d70",
   "metadata": {
    "papermill": {
     "duration": 0.003373,
     "end_time": "2025-07-30T19:40:19.187860",
     "exception": false,
     "start_time": "2025-07-30T19:40:19.184487",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submission\n",
    "Here is my submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b1c9115",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T19:40:19.196377Z",
     "iopub.status.busy": "2025-07-30T19:40:19.195699Z",
     "iopub.status.idle": "2025-07-30T19:40:19.331523Z",
     "shell.execute_reply": "2025-07-30T19:40:19.330507Z"
    },
    "papermill": {
     "duration": 0.1418,
     "end_time": "2025-07-30T19:40:19.333156",
     "exception": false,
     "start_time": "2025-07-30T19:40:19.191356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data[\"Transported\"] = my_model.predict(test_data[train_features])\n",
    "test_data[\"Transported\"] = test_data[\"Transported\"].map(lambda x: bool(x == 1.0))\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_data[\"PassengerId\"], 'Transported': test_data[\"Transported\"]})\n",
    "output.to_csv('sample_submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 3220602,
     "sourceId": 34377,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12.134889,
   "end_time": "2025-07-30T19:40:19.955988",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-30T19:40:07.821099",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
